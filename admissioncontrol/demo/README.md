# Basic Admission Control demo

In this demo we have one upstream, 5 downstream, and one Envoy.
There is one upstream. 

Bring down any running demo, and run this demo using 

```
docker-compose up --build -d 
```

## Configuration

```
          - name: envoy.filters.http.admission_control
            typed_config:
              '@type': type.googleapis.com/envoy.extensions.filters.http.admission_control.v3.AdmissionControl
              enabled:
                default_value: false
                runtime_key: admission_control.enabled
              sampling_window: 60s
              sr_threshold:
                default_value:
                  value: 95.0
                runtime_key: admission_control.sr_threshold
              aggression:
                default_value: 1.0
                runtime_key: admission_control.aggression
              rps_threshold:
                default_value: 1
                runtime_key: admission_control.rps_threshold
              max_rejection_probability:
                default_value:
                  value: 95.0
                runtime_key: admission_control.max_rejection_probability
              success_criteria:
                http_criteria:
                  http_success_status:
                  - start: 100
                    end: 400
                  - start: 404
                    end: 404
                grpc_criteria:
                  grpc_success_status:
                  - 0
                  - 1
```

Note that admission control is not actually enabled yet - see the `admission_control.enabled` runtime key.

## Sending moderate load to the upstream

We start off with each downstream sending 50 GRPC requests per second, which the upstream can serve.
Look at the [Grafana dash](http://localhost:3000/d/workshop/load-management-workshop?orgId=1&refresh=5s) and see 
that the requests are being served OK - you should see 250 rps being served with 200-class response codes.

Each individual downstream sends 50 requests per second, so total traffic is 50 requests per second.

## Upstream error rate spikes 

Now we set the upstream error rate to 20%: [20% error rate and 1000ms latency](http://localhost:9092/config?latency=100&error_rate=0.2)
Wait for a while for metrics to update and check the Grafana dashboard. You should see that the downstream is now returning about 20% error codes, with status code 13.
These come from the upstream. 

## Enable admission control 

Now let's enable admission control.
Edit `envoy.yaml`, and switch it on:

```
              enabled:
                default_value: true
                runtime_key: admission_control.enabled
```

Run `docker-compose restart envoy` so that Envoy will pick up these changes.

Note: in a more fleshed-out Envoy install you could change this on-the-fly without restarting Envoy by using a RTDS control plane. 

Now look at the dashboard again. You should see that there are now a population of error code 14 responses.
These are generated by Envoy admission control.
The rejection probability is around 20%, similar to the error rate.

## Increase error rate

Now we increase the error rate to 100%: [100% error rate and 1000ms latency](http://localhost:9092/config?latency=100&error_rate=1.0)
Watch, and you will see the rate of status code 13s increase - this is the change we just made taking effect.
Soon after, Envoy will start to greatly increase the number of code 14s, applying throttling.

The configuration above specifies that the maximum rejection probability is 95%. 
We are sending 250 requests per second, which are all erroring - so we should end up with around 237 code 14s per second - these are throttled - and the remainder, 
about 5% of the traffic, actually making it through to the upstream and receving a code 13 response.

## Reduce error rate to 50% and modify rps_threshold

Now we increase the error rate to 50%: [50% error rate and 100ms latency](http://localhost:9092/config?latency=100&error_rate=0.5)
We see Envoy reduce the rate of throttling and allow more through to the upstreams. 

Now let's experiment with modifying the `rps_threshold` parameter.

```
              rps_threshold:
                default_value: 300
                runtime_key: admission_control.rps_threshold
```

Run `docker-compose restart envoy` so that Envoy will pick up these changes.
We are sending under 300 rps so Envoy will stop throttling now, because the request rate is under the threshld. 
You should see this in the Upstream Request and gRPC Requests Made graphs in Grafana - an even split of gRPC status 1 and 13.

## Modifying success rate threshold

Change the `rps_threshold` to 1 to reenable throttling.

```
              rps_threshold:
                default_value: 1
                runtime_key: admission_control.rps_threshold
```

Run `docker-compose restart envoy` so that Envoy will pick up these changes.


Now let's modify the `sr_threshold` parameter. We currently have a 50% success rate for requests.
A `sr_threshold` value of 95.0, which we currently have, means that Envoy will not shed load until the request success rate falls below that level.

Let's change the `sr_threshold` to 80% as follows:

```
              sr_threshold:
                default_value:
                  value: 80.0
                runtime_key: admission_control.sr_threshold
```

Run `docker-compose restart envoy` so that Envoy will pick up these changes.

The request success rate is currently less than the threshold, so you will observe throttling.

Let's change the error rate to something under 20%: [10% error rate and 1000ms latency](http://localhost:9092/config?latency=100&error_rate=0.1)

Watch the graphs in Grafana: the throttling should stop, because the current error rate is below (1 - sr_threshold).

 Let's start throttling again by increasing the error rate above `sr_threshold`: [25% error rate and 1000ms latency](http://localhost:9092/config?latency=100&error_rate=0.25)

## Modifying aggression

Envoy's aggression parameter means that Envoy will throttle more aggressively as the error rate increases.
With aggression 1, and a 25% error rate with 250 requests per second, Envoy will throttle around 14 requests per second, or around 5% of the total offered traffic.

Let's change the aggression parameter 

```
              aggression:
                default_value: 5.0
                runtime_key: admission_control.aggression
```

Run `docker-compose restart envoy` so that Envoy will pick up these changes.

Wait for the change to take effect - you should see the throttling rate - code 14 responses - increase significantly, to around 50% of the offered traffic.

TODO observe different upstream performances
